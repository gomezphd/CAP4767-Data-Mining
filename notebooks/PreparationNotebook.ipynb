{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gomezphd/CAP4767-Data-Mining/blob/main/notebooks/PreparationNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Flight Delay Classifier Using Weather Data\n",
        "**Authors:** Barbara Lorenzo & Carlos C. Gomez  \n",
        "**Date:** December 2024\n",
        "\n",
        "# 1. Introduction\n",
        "\n",
        "## 1.1 Project Overview\n",
        "The goal of this project is to develop a binary classifier that predicts whether a flight will be delayed or not, based on both flight data and relevant weather data. Flight delays impact airlines by increasing operational costs and disrupting passengers' schedules, leading to dissatisfaction. If we can accurately predict delays, airlines can proactively mitigate their effects, improving operational efficiency and customer satisfaction.\n",
        "\n",
        "## 1.2 Business Value\n",
        "- Improved customer satisfaction through proactive delay notifications.\n",
        "- Better resource allocation for airlines.\n",
        "- Reduced operational costs through optimized scheduling.\n",
        "- Enhanced decision-making for both airlines and passengers.\n"
      ],
      "metadata": {
        "id": "UMTqV04pj5T2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# For machine learning model creation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "# For handling and combining multiple datasets\n",
        "from datetime import datetime\n",
        "\n"
      ],
      "metadata": {
        "id": "luCx0CnrpCQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Dataset Selection and Loading\n",
        "\n",
        "## 2.1 Dataset Selection\n",
        "We are using the \"US Flight Delay Data\" from Kaggle along with NOAA Weather Data to capture flight-specific and weather-specific features that may contribute to delays.\n",
        "\n",
        "## 2.2 Dataset Description\n",
        "We will use two datasets:\n",
        "1. **Flight Delay Data**: Historical flight records, including departure/arrival times and delay information.\n",
        "2. **Weather Data**: Corresponding weather conditions at airports during relevant times.\n",
        "\n",
        "## 2.3 Loading the Datasets\n",
        "We will upload the datasets to Google Colab, which will enable us to start the data cleaning, exploration, and preprocessing stages.\n"
      ],
      "metadata": {
        "id": "F4aXrc_Tu3wN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Upload flight dataset from local (you will be prompted to select a file)\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Load flight dataset into a DataFrame\n",
        "flight_data = pd.read_csv('flight_delay_data.csv') # replace with your file's name\n",
        "\n",
        "# Upload weather dataset from local (you will be prompted to select a file)\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Load weather dataset into a DataFrame\n",
        "weather_data = pd.read_csv('weather_data.csv') # replace with your file's name\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "oaO04sn3v6GU",
        "outputId": "f5c2858e-4b01-4b56-c4cf-e7019ccdc6aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8fe23d12-869e-4bf0-94da-52db698a5324\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8fe23d12-869e-4bf0-94da-52db698a5324\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-61842b81ace9>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Upload flight dataset from local (you will be prompted to select a file)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Load flight dataset into a DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yMCTGC-pu3tU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GwPzcbQRu3qb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "L43muxb7u3nA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Dataset Selection and Problem Statement\n",
        "\n",
        "## 1.1 Dataset Selection\n",
        "For this project, we are using datasets that contain information on flights and weather conditions. Specifically, we will combine the \"US Flight Delay Data\" from Kaggle with weather data from NOAA. This combination will allow us to capture both the flight-specific and weather-specific variables that may contribute to delays.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zkymSswckJGQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vMgfzzYcraS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload flight dataset from local (you will be prompted to select a file)\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Load flight dataset into a DataFrame\n",
        "flight_data = pd.read_csv('flight_delay_data.csv') # replace with your file's name\n"
      ],
      "metadata": {
        "id": "sLPnkCpXpFt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload weather dataset from local (you will be prompted to select a file)\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Load weather dataset into a DataFrame\n",
        "weather_data = pd.read_csv('weather_data.csv') # replace with your file's name\n"
      ],
      "metadata": {
        "id": "mvBQ4wxbpLv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Data Cleaning and Preprocessing\n",
        "\n",
        "## 2.1 Data Cleaning Plan\n",
        "1. **Handling Missing Values**: Missing data will be addressed by using imputation techniques like interpolation for numerical features or by dropping rows with critical missing values.\n",
        "2. **Converting Categorical Variables**: We will convert categorical variables such as airline codes into numerical formats using one-hot encoding, which allows the classifier to process these features effectively.\n",
        "3. **Scaling Numeric Features**: Numeric features such as temperature, wind speed, and visibility will be scaled using either **normalization** or **standardization**. This will ensure that our model is not biased by different value ranges.\n",
        "4. **Dataset Integration**: The flight and weather datasets will be combined based on **timestamps** and **location identifiers** to ensure proper alignment.\n",
        "5. **Feature Engineering**: New features such as a \"bad weather\" indicator will be created to capture severe weather conditions that are likely to influence flight delays.\n"
      ],
      "metadata": {
        "id": "Tm1DKdFikMxG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Exploratory Data Analysis (EDA)\n",
        "\n",
        "## 3.1 Univariate Analysis\n",
        "- We will perform univariate analysis to examine the distributions of flight delays, weather conditions (e.g., temperature, precipitation), and flight schedule variables (e.g., departure times).\n",
        "\n",
        "## 3.2 Bivariate Analysis\n",
        "- Bivariate analysis will help us understand the relationships between weather conditions and flight delays. For example, we will analyze how different weather features (e.g., wind speed, visibility) correlate with delays.\n",
        "\n",
        "## 3.3 Multivariate Analysis\n",
        "- Multivariate analysis will allow us to explore interactions among multiple features, such as how airline, weather, and flight schedule jointly affect the likelihood of delays.\n",
        "\n",
        "**Visualizations** will be created using **Matplotlib** and **Seaborn** to illustrate these relationships and uncover any important patterns that may guide feature selection and model building.\n"
      ],
      "metadata": {
        "id": "0JFWVrN9ms-V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Model Selection and Implementation\n",
        "\n",
        "We will develop and compare several classification models, including **Logistic Regression**, **Random Forest**, and **XGBoost**, to predict whether a flight will be delayed. Below is our modeling plan:\n",
        "\n",
        "## 4.1 Logistic Regression\n",
        "- As a baseline model, Logistic Regression provides a simple linear decision boundary to assess initial feature correlations.\n",
        "\n",
        "## 4.2 Random Forest\n",
        "- An ensemble-based classifier that captures non-linear relationships and is less prone to overfitting compared to individual decision trees.\n",
        "\n",
        "## 4.3 XGBoost\n",
        "- A more sophisticated gradient boosting algorithm known for excellent performance on tabular data, especially with heterogeneous features.\n",
        "\n",
        "The models will be evaluated using metrics such as **accuracy**, **precision**, **recall**, **F1-score**, and **AUC-ROC** to determine which approach best suits our problem.\n"
      ],
      "metadata": {
        "id": "jW73ruAwms7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Business Report Summary\n",
        "\n",
        "## 5.1 Introduction\n",
        "- The objective of this project is to predict flight delays by using both flight-specific and weather-related data. This can help airlines proactively manage scheduling and improve resource utilization.\n",
        "\n",
        "## 5.2 Methods\n",
        "- **Data Cleaning and Preprocessing**: Missing data imputation, categorical encoding, and feature scaling.\n",
        "- **Modeling**: We tested multiple models including Logistic Regression, Random Forest, and XGBoost, optimizing their hyperparameters for the best results.\n",
        "\n",
        "## 5.3 Results\n",
        "- We will summarize our findings, including model performance metrics and key insights on which factors are most influential in predicting delays.\n",
        "\n",
        "## 5.4 Conclusion\n",
        "- Predicting flight delays allows airlines to mitigate their effects through better scheduling and operational adjustments. However, limitations include potential inaccuracies in weather data and the unpredictability of operational disruptions.\n"
      ],
      "metadata": {
        "id": "eTuEkeAims5C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Innovation and Creativity\n",
        "\n",
        "## 6.1 Enhancements and Creative Methods\n",
        "- We will apply **weather severity indices** to improve predictions, combining weather features into a single \"severity\" measure to see how well it correlates with delays.\n",
        "- **Ensemble Modeling**: We plan to use an ensemble approach, combining **Random Forest** and **XGBoost** to enhance prediction robustness.\n",
        "- **Advanced Visualizations**: To better convey trends, we will create **animated visualizations** that show changes in flight status and delays over time.\n"
      ],
      "metadata": {
        "id": "6l85klFLms2C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Timeline and Submission\n",
        "\n",
        "## 7.1 Proposed Timeline\n",
        "- **Day _**: Dataset exploration and cleaning.\n",
        "- **Day _**: Conduct EDA and perform feature engineering.\n",
        "- **Day __**: Model selection, training, and testing.\n",
        "- **Day __**: Write the business report summarizing our project.\n",
        "- **Day __**: Finalize all deliverables and submit.\n",
        "\n",
        "## 7.2 Deliverables\n",
        "- **Colab Notebook**: Submitted as both `.ipynb` and `.html`.\n",
        "- **Business Report**: A well-polished PDF covering all aspects of the project.\n"
      ],
      "metadata": {
        "id": "KXVvDZaOmszY"
      }
    }
  ]
}